<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="AGrail">
  <meta property="og:title" content="AGrail"/>
  <meta property="og:description" content="A Lifelong Agent Guardrail with Effective and Adaptive Safety Detection"/>
  <meta property="og:url" content="https://github.com/EddyLuo1232/AGrail"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="AGrail">
  <meta name="twitter:description" content="A Lifelong Agent Guardrail with Effective and Adaptive Safety Detection">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->



  <title>AGrail</title>
  <link rel="icon" type="image/x-icon" href="static/images/icon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>
  
  <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
  
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://autodans.github.io/AutoDAN/">
            <b>AutoDAN</b> <p style="font-size:18px; display: inline; margin-left: 5px;">üî•</p>
          </a>
          <a class="navbar-item" href="https://arxiv.org/pdf/2410.05295">
            <b>AutoDAN-Turbo</b> <p style="font-size:18px; display: inline; margin-left: 5px;">üî•</p>
          </a>
           <a class="navbar-item" href="https://rain305f.github.io/AdaShield-Project/">
            <b>AdaShield</b> <p style="font-size:18px; display: inline; margin-left: 5px;">üî•</p>
          </a>
          <a class="navbar-item" href="https://fzwark.github.io/LLM-System-Attack-Demo/">
            <b>LLM System Attack</b> <p style="font-size:18px; display: inline; margin-left: 5px;">üî•</p>
          </a>
          <a class="navbar-item" href="https://jayfeather1024.github.io/Finetuning-Jailbreak-Defense/">
            <b>BackdoorAlign</b> <p style="font-size:18px; display: inline; margin-left: 5px;">üî•</p>
          </a>
          <a class="navbar-item" href="https://eddyluo1232.github.io/JailBreakV28K/">
            <b>JailBreakV</b> <p style="font-size:18px; display: inline; margin-left: 5px;">üî•</p>
          </a>
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              <img src="static/images/icon.png" alt="Icon" style="vertical-align: middle; margin-right: 5px; width: 70px; height: 70px;">
              AGrail: A Lifelong Agent Guardrail with Effective and Adaptive Safety Detection
            </h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://EddyLuo1232.github.io/" style="text-decoration: none; color: inherit;">Weidi Luo<sup style="color:#ed4b82;">1</sup></a>,</span>
                <span class="author-block">
                  <a href="https://scholar.google.com/citations?user=GUarSlcAAAAJ&hl=en" style="text-decoration: none; color: inherit;">Shenghong Dai<sup style="color:#6fbf73;">2</sup></a>,</span>
                  <span class="author-block">
                    <a href="https://sheltonliu-n.github.io/" style="text-decoration: none; color: inherit;">Xiaogeng Liu<sup style="color:#6fbf73;">2</sup></a>,</span>
                    <span class="author-block">
                    <a href="https://pages.cs.wisc.edu/~suman/" style="text-decoration: none; color: inherit;">Suman Banerjee<sup style="color:#6fbf73;">2</sup></a>,</span>
                    <span class="author-block">
                    <a href="https://u.osu.edu/ihudas/people/" style="text-decoration: none; color: inherit;">Huan Sun<sup style="color:#ed4b82;">1</sup></a>,</span>
                    <span class="author-block">
                    <a href="https://muhaochen.github.io/" style="text-decoration: none; color: inherit;">Muhao Chen<sup style="color:#7682aa;">3</sup></a>,</span>
                    <span class="author-block">
                    <a href="https://xiaocw11.github.io/" style="text-decoration: none; color: inherit;">Chaowei Xiao<sup style="color:#6fbf73;">2</sup></a>,</span>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup style="color:#ed4b82;">1</sup>The Ohio State University,</span>
                    <span class="author-block"><sup style="color:#6fbf73;">2</sup>University of Wisconsin‚ÄìMadison</span>
                    <span class="author-block"><sup style="color:#7682aa;">3</sup>University of California, Davis</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>


                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/EddyLuo1232/AGrail4Agent" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <!-- Your video here -->
        <source src="static/videos/workflow.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Prompt Injection Attack on Safe-OS
      </h2>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <!-- Your video here -->
        <source src="static/videos/workflow2.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Environment Attack on Safe-OS
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">üöÄ Abstract</h2>
        <div class="content has-text-justified">
          <p>
            The rapid advancements in Large Language Models (LLMs) have enabled their deployment as autonomous agents for handling complex tasks in dynamic environments. These LLMs demonstrate strong problem-solving capabilities and adaptability to multifaceted scenarios. However, their use as agents also introduces significant risks, including task-specific risks, which are identified by the agent administrator based on the specific task requirements and constraints, and systemic risks, which stem from vulnerabilities in their design or interactions, potentially compromising confidentiality, integrity, or availability (CIA) of information and triggering security risks. Existing defense agencies fail to adaptively and effectively mitigate these risks. In this paper, we propose AGrail, a lifelong agent guardrail to enhance LLM agent safety, which features adaptive safety check generation, effective safety check optimization, and tool compatibility & flexibility. Extensive experiments demonstrate that AGrail not only achieves strong performance against task-specific and system risks but also exhibits transferability across different LLM agents' tasks.
        </div>
        <div class="item" style="text-align: center;">
    <!-- Your image here -->
    <img src="static/images/workflow.png" alt="MY ALT TEXT" style="width: 100%; max-width: 100%;"/>
    <h2 class="subtitle has-text-centered" style="font-size: smaller;">
      Our AGrail features <strong>Adaptive Safety Check Generation</strong>, <strong>Effective Safety Check Optimization</strong>, and <strong>Tool Compatibility & Flexibility</strong>.
    </h2>
  </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">üîç Overview of Safe-OS</h2>
        <div class="content has-text-justified">
          <p>Considering the complexity of the OS environment and its diverse interaction routes‚Äîsuch as process management, user permission management, and file system access control‚ÄîOS agents are exposed to a broader range of attack scenarios. These include <strong>Prompt Injection Attack</strong>: Manipulating information in environment to alter the agent's actions, leading it to perform unintended operations (e.g., modifying agent output).
<strong>System Sabotage Attack</strong>: Directing the agent to take explicitly harmful actions against the system (e.g., corrupting memory, damaging files, or halting processes).
<strong>Environment Attack</strong>: An attack where an agent's action appears harmless in isolation but becomes harmful when considering the environment situation (e.g., rename file resulting in data loss). To address this challenge, we propose <strong>Safe-OS</strong>, a high-quality, carefully designed, and comprehensive dataset designed to evaluate the robustness of online OS agents. These attacks are carefully designed based on successful attacks targeting GPT-4-based OS agents. Additionally, our dataset simulates real-world OS environments using Docker, defining two distinct user identities: one as a root user with sudo privileges, and the other as a regular user without sudo access. Safe-OS includes both normal and harmful scenarios, with operations covering both single-step and multi-step tasks.</p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">üìë Features of AGrail</h2>
        <div class="content has-text-justified">
          <p>
            We propose a nova lifelong framework by leveraging collaborative LLMs to detect risks in different tasks adaptively and effectively.
          </p>
          <ul>
            <li><strong>Adaptive Safety Check Generation:</strong> A safety check refers to a specific safety verification item or policy within the overall risk detection process. Our framework not only dynamically generates adaptive safety checks across various downstream tasks based on universal safety criteria, but also supports task-specific safety checks in response to manually specific trusted contexts.
            </li>
            <li><strong>Effective Safety Check Optimization:</strong> Our framework iteratively refines its safety checks to identify the optimal and effective set of safety checks for each type of agent action during test-time adaptation (TTA) by two cooperative LLMs.
            </li>
            
            <li><strong>Tool Compatibility & Flexibility:</strong> In addition to leveraging the internal reasoning ability for guardrail, our framework can selectively invoke customized auxiliary tools to enhance the checking process of each safety check. These tools may include environment security assessment tools to provide an environment detection process.
            </li>
          </ul>
        </div>
        
      </div>
    </div>
  </div>
</section>


  <section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">‚úçÔ∏è Learning Analysis</h2>
        <div class="content has-text-justified">
          <p>AGrail's memory module enables lifelong learning by adaptively storing, optimizing, and generalizing safety checks across tasks, ensuring robust and evolving security for LLM agents. Here is the demo about the learning process: </p>
        </div>
             <video poster="" id="tree" autoplay controls muted loop height="100%">
        <!-- Your video here -->
        <source src="static/videos/workflow3.mp4"
        type="video/mp4">
      </video>
      </div>
    </div>
  </div>
</section>

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">üîî Evaluation</h2>
        <div class="content has-text-justified">
          <p> AGrail demonstrates strong performance in both task-specific and systemic risk detection. As shown in Tables 1 and 2, AGrail consistently ranks second across specific tasks (e.g., Mind2Web-SC and EICU-AC), regardless of using GPT-4o or Claude-3.5-Sonnet. In systemic risk detection on Safe-OS and AdvWeb, AGrail based on Claude-3.5-Sonnet achieves 0% ASR against prompt injection attacks on OS and AdvWeb, while blocking only 4.4% of benign actions on OS. When against environment and system sabotage attack attacks, ASR remain low at 5% and 3.8%. For EIA attacks, AGrail achieves 6% ASR in action grounding and 28% in action generation while maintaining 86.7% accuracy on normal web tasks, demonstrating the trade-off performance between robustness and effectiveness. In contrast, model-based defenses perform well in specific tasks but may block 49.2% of benign actions in Safe-OS, which show overly restrictive detection in these baselines. Even with task-specific safety criteria, LLaMA-Guard3 struggles to defend risks across these scenarios, which demonstrates that these LLM guardrails have difficulty in detecting these risks for LLM agents.</p>
        </div>
        <img src="static/images/result.png" alt="MY ALT TEXT" style="width: 100%; max-width: 100%;"/>
      </div>
    </div>
  </div>
</section>











<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the¬†<a href="https://nerfies.github.io" target="_blank">Nerfies</a>¬†project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
